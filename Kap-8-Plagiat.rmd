---
title: "Glanz und Misere des Plagiats. Zur Attraktivierung der Medien"
indent: true
output:
    html_document: default
bibliography: Rel-Bib.bib
lang: de-De
header-includes:
  - \usepackage[german=quotes]{csquotes}
---

Früher in der Öffentlichkeit wenig thematisiert, ist es jetzt beinah unmöglich, den Ausdruck _KI_ für künstliche Intelligenz zu verfehlen. Es ist die neue digitale Mediation _en vogue_, darum sich viele gesellschaftliche Debatten und Kontroversen drehen, seitdem diese Technologie unter dem Namen _ChatGPT_ -- GPT für _Generative Pretrained Transformers_ -- bekannt und im Internet zur Verfügung gestellt wurde. Wer _ChatGPT_ probiert hat, hat ein Gefühl dafür gewonnen, in welche Richtung die nächsten Entwicklungen im Internet und in den sozialen Medien gehen und welche möglicherweise weitreichende Veränderungen unsere Gesellschaften durchgehen würden, die heutzutage nicht mehr als von digitalen Relationen in der Form von zahlreichen Algorithmen vernetzten Gesellschaften weg zu denken sind [@Seyfert2019; @Seyfert2021]. _ChatGPT_ zeigt allen Akteuren und Instanzen unserer Gesellschaften vielleicht deutlicher als andere Mediationen zuvor, dass die Macht von Medien und im Allgemeinen von Mediationen deshalb so bewältigend ist, weil sie unsere Verhältnisse zu den anderen und zur Welt abfangen und reproduzieren können bzw. weil sie jede Stufe der Arbeit an relationalen Ereignissen entwickeln können, ohne dass dabei Akteure und gesellschaftliche Instanzen notwendig wären. Die Welt der Mediationen ist eine Welt, in der idealerweise nicht mehr die Akteure und die Kollektiven anhand von Verhältnissen die Mediationen dieser Verhältnisse kontrollieren, sondern diese Mediationen kontrollieren diese Verhältnisse anhand von Akteuren und Kollektiven. Deshalb bilden die Mediationen die Grundlage von einer eigenen Ordnung von Verhältnissen, die wie "an sich" existieren würden bzw. in der die Relation vollständig frei von menschlichen Merkmalen und in diesem Sinne als reine perfekte Relation erfolgen würde. Diese Ordnung von Verhältnissen fungiert als Grundlage bzw. Selbstverständnis der Medien orientierten Relationsstruktur. In dieser Relationsstruktur sollen die Mediationen die doppelte Einschreibung von Akteuren und Instanzen gewährleisten, diese Akteure auf Zirkulation bringen und die Position von Instanzen dieser Relationsstruktur stärken. Entsprechend arbeiten die Akteure und die Instanzen in dieser Relationsstruktur daran, die Mediationen möglichst unabhängig von der Kontrolle der Akteure und der gesellschaftlichen Instanzen zu machen, damit diese Mediationen ihre eigene Kontrolle in der Gewährleistung der doppelten Einschreibung von Akteuren und Instanzen entwickeln, die sich als die Bedeutung der Reziprozität und die Grundlage der Legitimation von Akteuren und Instanzen in dieser Relationsstruktur ergibt. Gleichzeitig ist diese Arbeit der Beleg für die Abweichung der Medien orientierten Relationsstruktur vom Ideal der perfekten Relation, was wiederum diese Relationsstruktur strukturiert und im Vergleich zu den anderen Relationsstrukturen ihre Identität als Ordnung von Verhältnissen gibt, die zur Attraktivität der Mediationen beitragen müssen. Diese Attraktivität ist das Hauptmerkmal und die Kernsequenz dieser Relationsstruktur. Sie ist der Punkt, ab der sie sich als selbstständige Relationsstruktur bildet.

Wie ist es dazu gekommen bzw. wie hat sich aus der Verselbständigung von Mediationen eine ganze Relationsstruktur gebildet? In diesem Kapitel beantworten wir diese Frage zuerst anhand von einem vertiefenden Blick in die Geschichte der Operationen, die ein Transformer durchführt. Dabei erklären wir einerseits, wie diese Operationen jede Stufe der Arbeit an relationalen Ereignissen abfangen, die zum einen auf Mediationen transferiert werden und zum zweiten an diesen Mediationen miteinander verbunden werden. Diese zwei Schritte sollen zur Attraktivität dieser Mediation als Repräsentanten nicht nur von anderen Mediationen, sondern und wie oben hervorgehoben auch und vor allem von der sozialen Arbeit an relationalen Ereignissen beitragen. Aus der erfolgreichen Entwicklung von diesen Schritten ergibt sich, wie und wie weit diese Mediationen in Relationsstrukturen durchgesetzt werden können. In dieser Hinsicht und in Verbindung mit der KI als Transformer kann deshalb gefragt werden, wie sie sich tatsächlich durchsetzen kann und welche Folgen ihre mögliche Durchsetzung hat. Um diesem letzten Punkt besser veranschaulichen zu können, machen wir abschließend ein Parallel mit einer anderen Mediation, die sich erfolgreich durch alle Relationsstrukturen verbreitet hat: Das Geld.

## Transformers als relationale Dispositiven

Die Theorie der Relation versteht Mediationen als Träger von Verhältnissen, davon die jeweiligen Mediationen ein Prinzip des Arrangements dieser Verhältnisse darstellen. Deshalb versteht sie Mediationen nicht nur im Sinne von Trägern von Funktionen oder von Formen, sondern auch als relationale Dispositiven. Damit solche relationale Dispositiven erfolgreich entwickelt werden, ist es jedoch erforderlich, dass Mediationen zu abstrakteren Mediationen entwickelt werden. Nur so können unterschiedliche Verhältnisse bzw. Verhältnisse, die auf unterschiedliche Kontexte verweisen, miteinander verbunden werden, ohne dass die jeweiligen Kontexte, die als Organisationsrahmen und Sinnzusammenhang der entsprechenden Verhältnisse gelten, diese Verbindungen schwächen oder stören. Diese Abflachung von Kontexteffekten macht aus Mediationen mächtige Akkumulatoren und Generatoren von Verhältnissen, die überall in Relationsstrukturen und Sequenzen von Relationsstrukturen verbreiten werden können, was der Art und Weise entspricht, wie die Medien orienterten Relationsstruktur die anderen Relationsstruktur zum Vorteil der eigenen Verbreitung und der Verbreitung der eigenen Fassung der Reziprozität als medialer Kontrolle satellisiert. Ein solches Verfahren ist dasjenige, dass in der Forschung zu Sprachen und zur Modellierung von Sprachen seit den 1950er Jahren entwickelt wurde, davon die Transformers wie _Generative Pretrained Transformers_ das zeitgenössische Ergebnis sind [@Hutchins1995].

Sprachmodelle wurden entwickelt, um das spezifische Problem der Übersetzung von einer Sprache in eine andere Sprache mit Hilfe eines Rechners zu lösen (ebd.). Bis in die 1980er Jahren erweisen sich die meist mit Unterstützung von der Firma _IBM_ durchgeführten Übersetzungsexperimente jedoch als bescheiden. Mit einem Rechner war es möglich, Begriffe in einer begrenzten Anzahl von Texten zu übersetzen, die anhand von einem statistischen Verfahren in Sätzen aufgegriffen und übersetzt wurden. Jedoch konnte ein solches Verfahren keine langen Wortfolgen wie etwa lange Sätze verarbeiten. Es gaben häufig Fehler, die ein menschliches Eingreifen zur Überprüfung und Korrektur der Übersetzung erforderten [@Pierce1966; @Zong2022]. Der technische Fortschritt, insbesondere die Steigerung der Rechenleistung (bessere _Central Processing Unit_ und _Graphics Processing Unit_) und des Arbeitsspeichers hat dazu geführt, dass einerseits größere Datenmengen gespeichert werden konnten und andererseits den Umfang von statistischen Operationen über diese Daten erweitert werden konnten. Aus dieser Entwicklung ergibt sich Mitte der 1980er Jahre das _Recurrent Neural Network_ (RNN). Es beschreibt eine Methode, die Verhältnisse zwischen Begriffen in Sprachen auf der Grundlage der Modellierung von Verhältnissen zwischen Neuronen im menschlichen Gehirn auffasst. Mit der RNN-Methode können mehr Korrespondenzen zwischen Begriffen hergestellt -- das sog. _deep learning_ Ansatz  -- und gleichzeitig mit größeren Wortzusammenstellungen gearbeitet werden. Daraus sind ausgefeilteren Sprachmodellen wie etwa das Modell der bidirektionalen rekurrenten neuronalen Netzwerken (BRNN), das Langzeitgedächtnismodell (LSTM) oder das _gated recurrent units_ (GRUs) Modell konstruiert worden [siehe @Hochreiter1997]. Solche Modelle sind Matrixen von Verbindungen zwischen Begriffen, die nach einem Ähnlichkeitsansatz quantitativ gewertet werden. Begriffe, die stark verbunden sind, gelten als Begriffe, die auf ähnliche Inhalte verweisen. Begriffe, die dagegen schwach verbunden sind, verweisen auf unterschiedliche Inhalte. Ein solches Sprachmodell kann dann als eine Referenzmatrix verwendet werden, um weiter Sammlungen von sprachlichen Daten zu untersuchen und deren Inhalt zu werten.

Selbst mit der weiteren Entwicklung von Rechnern bleibt es jedoch schwierig, solche Sprachmodelle auf große Datensammlungen anzuwenden. Oft reichen die rechnerischen Kapazitäten oder die Speicherkapazitäten von gewöhnlichen Rechnern nicht aus. Anfang 2017 wurden deshalb GPT-Modelle entwickelt, die dieses Problem lösen sollten. Das innovative Merkmal von GPT-Modellen besteht darin, Matrixen von Begriffen nicht mit Sequenzen von Begriffen -- etwa mit Sätzen -- zu verbinden, sondern mit einzelnen Begriffen. Ein Transformer verbindet also ein Begriff mit den Begriffen, die am wahrscheinlichsten mit ihm in einer bestimmten Sprache auf der Grundlage von einer bestimmten Datensammlung verbunden sind. GPT-Modelle sind deshalb einerseits eine Erweiterung der Sprachmodelle, die nach einem _deep learning_ Ansatz konstruiert wurden. Andererseits besteht ihre Besonderheit darin, dass sie aufgrund von solche Matrixen die Wahrscheinlichkeit schneller und mit wenigen rechnerischen Kosten bestimmen können, dass ein Begriff _B_ nach einem Begriff _A_ auf der Grundlage von einem Kontext von Begriffen auftaucht, die am wahrscheinlichsten mit dem Begriff _A_ in einer gegebenen Sprache verbunden sind [siehe auch @Devlin2019]. In künftigen Versionen von solchen Transformern handelt es sich darum, das Ergebnis dieser Wahrscheinlichkeitsrechnung zu benutzen, um die Effizienz des Sprachmodells selbst bzw. um die Genauigkeit der Matrixen zu erhöhen, damit solche Wahrscheinlichkeitsrechnungen schneller und präziser erfolgen, ohne dass die rechnerischen Ressourcen zu sehr steigen. Bei Transformers geht es also um die Akkumulation von Dateien und von Verbindungen zwischen diesen Dateien, die erlauben, weitere Verbindungen zwischen diesen Dateien und entsprechend weitere Dateien aus diesen Verbindungen zu generieren. Solche Akkumulation anhand und in der Form von Mediationen zu entwickeln, sind jedoch nicht erst mit der wissenschaftlichen Arbeit an der KI entstanden. Sie stellen eine Grundtendenz beim Einbezug von Mediationen durch Akteure und gesellschaftliche Instanzen dar. Mediationen eröffnen Möglichkeiten zum weiteren Abgreifen von Verhältnissen, was die Akkumulationsmacht von Mediationen stärkt und zur Stärkung ihrer Symbolisierungsmacht und Formalisierungsmacht beiträgt. Dies macht Mediationen für Akteure und gesellschaftliche Instanzen attraktiv, auch wenn dabei sich diese Mediationen der Kontrolle von Akteuren und Instanzen immer mehr entziehen. Nehmen wir ein Beispiel, dass mit einer Grundlageoperation von Transformers verbunden ist: Lesen.

## Lesen

Transformers lesen Dateien, und wenn wir dieses Lesen von Außen betrachten würden, würden wir sagen, dass dieses Lesen nichts mit dem Lesen von Texten durch übliche menschlichen Akteuren gemein hat. Transformers nehmen Texte auf, die in diesem Sinne gelesen werden, dass sie von unerwünschten Zeichen und Begriffen gereinigt und in der Form von Vektoren dargestellt werden, die die Grundlage für die Berechnung von Verbindungen zwischen Begriffen und damit die notwendige Stufe zum Arrangement von solchen Verbindungen in der Form von einem anderen Text bereitstellen. Aus diesem Grund haben Transformers Debatten über den Wert nicht nur vom Lesen, sondern im Allgemeinen vom Wissen als Produktion aus der Interaktion zwischen Menschen und digitalen Technologien eingeführt, die teilweise auf die Debatten über verteilte Kognition in den Neuro- und Kognitionswissenschaften zurückgeht [@Magnus2007; @Michaelian2013; @Anderson2018; @Risku2020] sowie auf die Debatten zur Rolle von Algorithmen bei der Unterstützung menschlicher Entscheidungen zurückführen [@Pariser2012; @Anderson2012; @Braverman2014; @Bucher2018; @LeeLarsen2019]. Die Fragen, die sich in diesen Zusammenhängen stellen, betreffen den Wert von einer solchen Produktion vom Wissen und von dem entsprechenden Wissensinhalt, wenn diese nicht primär von menschlichen Akteuren, sondern maßgeblich von Mediationen produziert werden. Die Auseinandersetzung mit dem Lesen und seiner Geschichte sowie mit den Operationen, die mit dem Lesen verbunden sind, zeigt, dass solche Fragen nicht neu sind.

Soll es laut oder leise, schnell oder langsam gelesen werden? Hinter dieser Frage stecken Debatten zu der Entwicklung der Praktiken des Lesens, die deshalb nicht endgültig abgeschloßen werden können, weil sie das Problem der Hierarchisierung von Mediationen betreffen, das mit Satellisierungsstrategien innerhalb von Relationsstrukturen und zwischen Relationsstrukturen verbunden ist. Im Fall vom lauten bzw. leisen Lesen wird ersichtlich, die Verbreitung des leisen Lesens im Laufe der Zeit das laute Lesen nicht verabschiedet: "Das lautlose Lesen verdrängte nicht das laute Lesen, das weiterhin nicht nur beim Vorlesen, sondern auch beim 'Für-sich'-Lesen praktiziert wurde" [@Zedelmaier2001, 14; vgl. auch @Bickenbach2017]. Vielmehr wird beim Lesen nicht nur lautes und lautloses Lesen kombiniert, sondern noch mit dem langsamen und mit dem schnellen Lesen je nachdem gepaart, ob das Lesen menschzentriert oder nicht menschenzentriert betrachtet wird. Mit dem lauten Lesen wird nicht nur abstrakt und allgemein den Menschen ins Zentrum des Lesens gerückt, sondern der Phonozentrismus, wie es Jacques Derrida beschrieb [@Derrida1967], ist gleichzeitig die Signatur der Inkorporierungsmacht des Lesens durch das Aussprechen des Geschriebenen, die Herraschft des Wortes durch die Macht dessen Klang und damit die Herrschaft des Sprechers oder des Rezitators über den leisen Leser, der die Worten nicht erlebt, sondern nur sieht und deren Inhalt deshalb nur oberflächlich betrachten kann. Sei es in der griechischen Antike oder im 19. Jahrhundert und trotz der Revolution in der Produktion von schriftlichen Mediationen, die den Buchdruck im 16. Jahrhundert bringt und das lautlosen Lesen zu begünstigen scheint, setzt sich diese Unterscheidung -- wenn nicht diese Konkurrenz -- zwischen dem lauten und dem lautlosen Lesen weiter durch [@Gavrilov1997], die in der Theorie der Relation als ein Versuch abgebildet werden kann, unterschiedliche Hierarchieprinzipien zur Hervorhebung der Bedeutung von Sequenzen und von Institutionen in den Sequenzen von einer Relationsstruktur einzuführen. In der griechischen Antike wie im Mittelalter wird das laute Lesen häufig als gewöhnliche Praktik des Lesens vorgesehen, wenn das leise und das lautlose Lesen ein Sonderfall vom lauten Lesen darstellen [@Busch2002; vgl. auch @Bickenbach2017, 40ff.]. Mit dem lauten Lesen wird oft die Art vom Schriftstück verbunden -- laut werden literarische Werke gelesen, wenn dagegen das leise Lesen eher mit alltäglichen Schriften in Verbindung gebracht werden. Lautes und leises Lesen werden oft von professionnellen Lesern praktisiert, die das leise Lesen als eine Art von Hilfsmittel gebrauchen, um sich den Inhalt von Werken, die schon gelesen wurden oder manchmal auswendig gelernt wurden, wieder in Erinnerung zu bringen. Mit dem lauten Lesen kommt ebenfalls oft das langsame Lesen in Verbindung, und dabei wird hervorgehoben, dass laut lesen nicht nur als Kunst der Rhetorik praktisiert wird, sondern auch einerseits als Kontrollmittel vom Autor über den Leser, damit der Leser richtig bzw. im Sinne des Autors des Textes diesen Text versteht, und andererseits als Kontrolle des Wissens, das der Text mit sich bringt.

Wie Bickenbach am Beispiel von Christoph Martin Wieland hervorhebt, kommt dieses Thema der Kontrollverlust des Autors über seinen Text im 18. Jahrhundert vor, wenn es mehr und mehr wahrgenommen wird, dass die Leser im Grunde so lesen, wie sie wollen (ebd., 31). Für die Autoren wie Wieland oder später auch Arthur Schopenhauer und Friedrich Nietzsche birgt sich in dieser Gleichgültigkeit des Lesens die Gefahr, den Text mit eigenem Wissen zu interpretieren, das mit dem Autors Wissen nicht übereinstimmt, was dazu führen würde, den Text falsch zu verstehen. Dabei kann nur ein aufmerksames und langsames lautes Lesen helfen, oder wie Bickenbach am Beispiel von Nietzsche sagt: "Lesen wäre im Idealfall das Ablesen der Tatsachen ohne Verfälschung der eigenen Interpretation" (ebd., 41). Das, was im Fall von Nietzsche zur Vorbereitung der Grundlage seiner Kulturkritik der Moderne führt, wo das laute Lesen als Erbe der Antike die einzige adequate Technik zum richtigen Verständnis von Texten als physische Leistung vom Leser zur Gewährleistung der Einverleibung der realen Intentionen des Textautors wahrgenommen wird, zeigt im Fall der soziokulturellen Relationsstruktur, wie das Lesen als Mediation weitere Mediationen hierarchisiert und entsprechende Hierarchisierungsprinzipien zum Vorteil von bestimmten Sequenzen dieser Relationsstruktur durchsetzt. Sei es am Beispiel von Wieland oder von Nietzsche, zeigt die Erweiterung des Kreises der Leserschaft -- von kleinen Kreisen ausgebildeter Akteuren vor dem 18. Jahrhundert auf immer mehr Akteure nach dem 18. Jahrhundert und entsprechend auf ein wachsendes Publikum von Texten -- die größere Bedeutung der Attraktivität von Texten durch die gesellschaftlichen Instanzen, die wie die spezialisierte literarische Kritik oder der literarischen Magazinen daran arbeiten, solche Texte nicht nur attraktiver zu machen, sondern sie in Bezug auf diese Attraktivität zu werten. Das Problem, das die spezialisierte Kritik sowie die literarischen Magazinen adressieren, ist weniger dasjenige, dass Wieland und Nietzsche hervorheben, wenn sie die Rolle des Autors des Textes als _auctoritas_ im Bereich des Verstehens vom Text und daher als Sprachohr des richtigen Wissens perspektivieren und somit, wie Roland Barthes und zu einem gewissen Punkt auch Michel Foucault nahelegen, zu überschätzen tendieren [@Barthes1984; @Foucault1969]. Kritiker und Magazinen fokussieren die Texten im Text, die sie nicht unabhängig vom Autoren und von den Autoren betrachten, die am Text mittelbar und unmittelbar mitwirken, und die sie nicht mehr nur in Bezug vom Wissen werten, sondern allgemeiner von seiner Effektivität in der Unterstützung von Zirkulationen, von seiner Durchsetzungkraft als Mediation von allen möglichen Zirkulationen, die andere Mediationen bzw. andere Texte und andere Autoren im Gang setzen oder überlaufen. Mit der Kritik im spezialisierten und im nicht spezialisierten Sinne bekommt die Attraktivität als Sequenz der soziokulturellen Relationsstruktur eine wichtige Bedeutung als diese Sequenz, in der die Umverteilung von textuellen Mediationen zur Effizienz der Zirkulationen in der soziokulturellen Relationsstruktur stattfindet, die entsprechend die Gründung und Entwicklung von damit verbundenen Tätigkeitsbereichen fördert, was zur Vervielfältigung und zur Stratifizierung des Angebots von Texten mit entsprechenden Publika und mit entsprechenden Techniken des Lesens, des Interpretierens und des Schreibens ab dem 19. Jahrhundert führt. Dabei verschwinden die Techniken des lauten und des lautlosen Lesens nicht, sondern die Asymetrie, die dem lauten Lesen die Priorität gegenüber dem lautlosen Lesen hatte, entwickelt sich mehr und mehr in die Richtung von zahlreichen weiteren Interkationen zwischen beiden Techniken, die zur Verselbständigung einer Ordnung von Verhältnissen, die vollständig durch die gesellschaftlichen Effizienz von Mediationen, Zirkulation zu fördern und in Sequenzen zu organisieren, strukturiert werden würde.

Wie es Bourdieu schon merkte, hat man hier mit der Einführung von "Prinzipien der Vision und Division" der Welt -- und am Beispiel der Literatur und der Produktion von Texten sind es die Prinzipien der Vision und Division der literarischen Welt -- zu tun, die die Kritiken, die literarischen Magazinen und weitere Journalisten, die sich speziell mit der Welt der Literatur beschäftigen, durchsetzen wollen [etwa @Bourdieu1991, 13]. Und wenn diese Kritiker solche Prinzipien durchsetzen wollen, ist es nach Bourdieu im Dienst von Institutionen in anderen sozialen Feldern, die die Autonomie des literarischen Feldes entkräften wollen -- etwa nach der Opposition zwischen der künstlerischen Kultur der Künstler und der nicht künstlerischen bzw. schulischen, journalistischen, institutionellen Kunstkultur der Kritiker. Eine solche Externalität der Kritik der Kritiker, die bei Bourdieu unmittelbar die Nachfrage von künstlerischen Werken beeinflusst und somit dazu beiträgt, dass die anerkannten Künstler gleichzeitig diejenige sind, davon das Werk vom Publikum am meisten nachgefragt wird, zeigt gut, wie die Hierarchie der Künstler einer Hierarchie der Nachfrage von künstlerischen Werken folgen kann. Dabei stimmt diese Hierarchie nicht mit derjenige überein, die aus der Anerkennung zwischen Künstlern auf der Grundlage von ihrer Investition in die Kunst -- _lato sensu_, also in die Literatur, die Malerei, die Musik, die Bildhauerei usw. -- entsteht. Jedoch was Bourdieu als einen Machteinfluss von externen Feldern auf die Kunst und hier speziell die Literatur versteht, berücksichtigt nicht die Veränderung in der Produktion von Kunst selbst, das nicht nur das Publikum betrifft, die die Kunst kauft, sondern ebenfalls dasjenige, das Kunst produziert, dazu die Kritiker häufig ebenfalls gehören. Selbst die innere Revolution in der Malerei mit dem _Salon des Refusés_, in der Bourdieu der Ausgangspunkt der Konstitution von einem autonomen Feld der Kunst sieht, bleibt in seiner Erwähnung lediglich nur der _acte fondateur_ der Kunst als Feld. Das dort eine andere Art der Produktion von Kunst und einer entsprechenden Erneuerung der Kriterien der Kunst durch die wachsende Demokratisierung der Kunst und deren Kriterien passiert, die entsprechend mehr Akteure zu sich attraktiviert, die sich vorstellen können, Kunst zu machen und Künstler zu werden -- vom Einfluss des Ausbildungssystems und der Hervorhebung der Kultur als Dinstinktionsmerkmal ganz abgesehen --, wird nicht thematisiert. Erst wenn solche demographische und soziokulturelle Merkmale berücksichtigt werden, erscheint die Externalität, davon Bourdieu spricht, weniger diejenige zwischen zwei Feldern, die auf der Grundlage von anderen Hierarchieprinzipien und von einer anderen _illusio_ funktionieren würden, sondern von zwei Sequenzen in der selben Relationsstruktur, in der die Sequenz Attraktivität durch die Steigerung des Publikums, das sich für Kunst interessiert, lesen kann und durch das Ausbildungssystem mehr von der Kunst kennt, dazu ermutigt und ermächtigt wird, zu dieser Relationsstruktur zu zirkulieren.

Eine Folge aus dieser Vermehrung der Produzenten wie der Konsumenten von Kunst ist nicht nur die Personalisierung der Art und Weise, wie man liest, sondern im Allgemeinen die Desakralisierung der _auctoritas_ bzw. des einmaligen Merkmals der Verbindung zwischen einem Autor und seinem Werk zum Vorteil der Hervorhebung der Mediation "Kunst" in ihrer Komplexität -- am Beispiel der Literatur und im Allgemeinen der Texte zur Hervorhebung der Einbettung von Texten und deren entsprechenden Autoren in Texten. Kunst ist deshalb im Verständnis der Gesellschaften ab dem 19. Jahrhundert in diesem Sinne nicht mehr nur der Gegenstand, der als Kunstwerk gilt, sondern die Ideen, Konzepte, Kunsttechniken, Kunsttraditionen und entsprechende Autoren wenn nicht Strömungen, die in einem Kunstwerk mehr oder weniger explizit erwähnt bzw. zitiert werden, davon die Dekodierung durch Kritiker zur Kultivierung des Publikums und zur Kulturalisierung der Kunst selbst beiträgt. Dabei geht es primär um die Verdichtung der Mediation, um ihre Kapazität, andere Mediationen als ihre eigenen Merkmale zum eigenen Vorteil dieser Mediation zu harmonieren und zu transportieren. Diese Techniken sind an sich nicht in der Moderne geboren und auch nicht dort mit diesem Ziel der Ermächtigung von Mediationen im Einsatz gekommen, wie die Operation, die das Lesen oft begleitet, zeigt: das Exzerpieren.

## Exzerpieren




Wie Alain de Libera mit Fokus auf das Mittelalter sagt: "Die mittelalterliche Textualität ist, wenn man so will, eine mündliche Textualität; der mittelalterliche Text ist eine Mischung aus mündlichen und schriftlichen Texten, wobei das Mischungsverhältnis selbst für den modernen Leser manchmal nicht greifbar und fast immer unklar ist" [@Libera1984, 18]. Oder anders gesagt: Der Vermischung zwischem dem lauten und lautlosen Lesen, die von der Antike bis in der Neuzeit festgestellt wird, entspricht einer Vermischung von Mündlichem und Schriftlichem in den Texten selbst, die im Mittelalter -- im Fall von de Libera vom 12. bis zum 15. Jahrhundert -- als Wissensstrategie entwickelt wird, um die Überzeugungskraft des Textes selbst zu stärken, wobei "einen Text zu 'lesen' ihn in Verbindungen zu bringen bedeutet" (ebd., 28). Dies zeigt die Bedeutung der Mündlichkeit in den Texten des Mittelalters als Stütze der Erkenntnisentwicklung, die insbesondere in der Praktik des Zitierens und des Exzerpierens hervorgehoben wird. Beim Zitieren und beim Exzerpieren verwenden die Gelehrten sowohl den explizit Gesagten -- kontextualisierte Zitaten oder Erwähnungen von Textstellen aus anderen Texten bzw. von anderen Autoren --, als auch den Nahegelegten -- die Paraphrase --, als auch den Nicht-Gesagten -- die Verwendung von Textstellen anderer ohne Verweis auf die Quelle bzw. als stillschweigende Übernahme von Argumenten Dritter. Dabei geht es darum, dem Text eine "gute" Autorität zu geben, und dazu gehört es, dass das Wiederverwendete nicht als solches wahrgenommen wird: "Das Autoritätsargument wird von den Mittelalterlichen immer noch als einer der niedrigsten, wenn nicht der niedrigste theologische Ort. Der edle Gebrauch von Autorität, d.h. der richtige Gebrauch eines Textes, eines Satzes oder eines Fragments, ist still: Es ist nicht einmal die Intertextualität, sondern die Intratextualität, die Assimilation, die Abwendung, die Wiederverwendung des Anderen, die Verwischung des Unterschieds, die Totalisierung des Diskurses" (ebd. 26). Wenn das Lesen insbesondere den Text mit dem Gedächtnis des Lesers verbindet, sollen die Techniken des Zitierens und Exzerpierens das Gedächtnis der Leser zum Vorteil von einem künftigen Leser in den Text bringen. Diese Darstellung vom
