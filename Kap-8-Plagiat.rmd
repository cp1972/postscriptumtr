---
title: "Glanz und Misere des Plagiats. Zur Attraktivierung der Medien"
indent: true
output:
    html_document: default
bibliography: Rel-Bib.bib
lang: de-De
header-includes:
  - \usepackage[german=quotes]{csquotes}
---

Früher in der Öffentlichkeit wenig thematisiert, ist es jetzt beinah unmöglich, den Ausdruck _KI_ für künstliche Intelligenz zu verfehlen. Es ist die neue digitale Mediation _en vogue_, darum sich viele gesellschaftliche Debatten und Kontroversen drehen, seitdem diese Technologie unter dem Namen _ChatGPT_ -- GPT für _Generative Pretrained Transformers_ -- bekannt und im Internet zur Verfügung gestellt wurde. Wer _ChatGPT_ probiert hat, hat ein Gefühl dafür gewonnen, in welche Richtung die nächsten Entwicklungen im Internet und in den sozialen Medien gehen und welche möglicherweise weitreichende Veränderungen unsere Gesellschaften durchgehen würden, die heutzutage nicht mehr als von digitalen Relationen in der Form von zahlreichen Algorithmen vernetzten Gesellschaften weg zu denken sind [@Seyfert2019; @Seyfert2021]. _ChatGPT_ zeigt allen Akteuren und Instanzen unserer Gesellschaften vielleicht deutlicher als andere Mediationen zuvor, dass die Macht von Medien und im Allgemeinen von Mediationen deshalb so bewältigend ist, weil sie unsere Verhältnisse zu den anderen und zur Welt abfangen und reproduzieren können bzw. weil sie jede Stufe der Arbeit an relationalen Ereignissen entwickeln können, ohne dass dabei Akteure und gesellschaftliche Instanzen notwendig wären. Die Welt der Mediationen ist eine Welt, in der idealerweise nicht mehr die Akteure und die Kollektiven anhand von Verhältnissen die Mediationen dieser Verhältnisse kontrollieren, sondern diese Mediationen kontrollieren diese Verhältnisse anhand von Akteuren und Kollektiven. Deshalb bilden die Mediationen die Grundlage von einer eigenen Ordnung von Verhältnissen, die wie "an sich" existieren würden bzw. in der die Relation vollständig frei von menschlichen Merkmalen und in diesem Sinne als reine perfekte Relation erfolgen würde. Diese Ordnung von Verhältnissen fungiert als Grundlage bzw. Selbstverständnis der Medien orientierten Relationsstruktur. In dieser Relationsstruktur sollen die Mediationen die doppelte Einschreibung von Akteuren und Instanzen gewährleisten, diese Akteure auf Zirkulation bringen und die Position von Instanzen dieser Relationsstruktur stärken. Entsprechend arbeiten die Akteure und die Instanzen in dieser Relationsstruktur daran, die Mediationen möglichst unabhängig von der Kontrolle der Akteure und der gesellschaftlichen Instanzen zu machen, damit diese Mediationen ihre eigene Kontrolle in der Gewährleistung der doppelten Einschreibung von Akteuren und Instanzen entwickeln, die sich als die Bedeutung der Reziprozität und die Grundlage der Legitimation von Akteuren und Instanzen in dieser Relationsstruktur ergibt. Gleichzeitig ist diese Arbeit der Beleg für die Abweichung der Medien orientierten Relationsstruktur vom Ideal der perfekten Relation, was wiederum diese Relationsstruktur strukturiert und im Vergleich zu den anderen Relationsstrukturen ihre Identität als Ordnung von Verhältnissen gibt, die zur Attraktivität der Mediationen beitragen müssen. Diese Attraktivität ist das Hauptmerkmal und die Kernsequenz dieser Relationsstruktur. Sie ist der Punkt, ab der sie sich als selbstständige Relationsstruktur bildet.

Wie ist es dazu gekommen bzw. wie hat sich aus der Verselbständigung von Mediationen eine ganze Relationsstruktur gebildet? In diesem Kapitel beantworten wir diese Frage zuerst anhand von einem vertiefenden Blick in die Geschichte der Operationen, die ein Transformer durchführt. Dabei erklären wir einerseits, wie diese Operationen jede Stufe der Arbeit an relationalen Ereignissen abfangen, die zum einen auf Mediationen transferiert werden und zum zweiten an diesen Mediationen miteinander verbunden werden. Diese zwei Schritte sollen zur Attraktivität dieser Mediation als Repräsentanten nicht nur von anderen Mediationen, sondern und wie oben hervorgehoben auch und vor allem von der sozialen Arbeit an relationalen Ereignissen beitragen. Aus der erfolgreichen Entwicklung von diesen Schritten ergibt sich, wie und wie weit diese Mediationen in Relationsstrukturen durchgesetzt werden können. In dieser Hinsicht und in Verbindung mit der KI als Transformer kann deshalb gefragt werden, wie sie sich tatsächlich durchsetzen kann und welche Folgen ihre mögliche Durchsetzung hat. Um diesem letzten Punkt besser veranschaulichen zu können, machen wir abschließend ein Parallel mit einer anderen Mediation, die sich erfolgreich durch alle Relationsstrukturen verbreitet hat: Das Geld.

## Transformers als relationale Dispositiven

Die Theorie der Relation versteht Mediationen als Träger von Verhältnissen, davon die jeweiligen Mediationen ein Prinzip des Arrangements dieser Verhältnisse darstellen. Deshalb versteht sie Mediationen nicht nur im Sinne von Trägern von Funktionen oder von Formen, sondern auch als relationale Dispositiven. Damit solche relationale Dispositiven erfolgreich entwickelt werden, ist es jedoch erforderlich, dass Mediationen zu abstrakteren Mediationen entwickelt werden. Nur so können unterschiedliche Verhältnisse bzw. Verhältnisse, die auf unterschiedliche Kontexte verweisen, miteinander verbunden werden, ohne dass die jeweiligen Kontexte, die als Organisationsrahmen und Sinnzusammenhang der entsprechenden Verhältnisse gelten, diese Verbindungen schwächen oder stören. Diese Abflachung von Kontexteffekten macht aus Mediationen mächtige Akkumulatoren und Generatoren von Verhältnissen, die überall in Relationsstrukturen und Sequenzen von Relationsstrukturen verbreiten werden können, was der Art und Weise entspricht, wie die Medien orienterten Relationsstruktur die anderen Relationsstruktur zum Vorteil der eigenen Verbreitung und der Verbreitung der eigenen Fassung der Reziprozität als medialer Kontrolle satellisiert. Ein solches Verfahren ist dasjenige, dass in der Forschung zu Sprachen und zur Modellierung von Sprachen seit den 1950er Jahren entwickelt wurde, davon die Transformers wie _Generative Pretrained Transformers_ das zeitgenössische Ergebnis sind [@Hutchins1995].

Sprachmodelle wurden entwickelt, um das spezifische Problem der Übersetzung von einer Sprache in eine andere Sprache mit Hilfe eines Rechners zu lösen (ebd.). Bis in die 1980er Jahren erweisen sich die meist mit Unterstützung von der Firma _IBM_ durchgeführten Übersetzungsexperimente jedoch als bescheiden. Mit einem Rechner war es möglich, Begriffe in einer begrenzten Anzahl von Texten zu übersetzen, die anhand von einem statistischen Verfahren in Sätzen aufgegriffen und übersetzt wurden. Jedoch konnte ein solches Verfahren keine langen Wortfolgen wie etwa lange Sätze verarbeiten. Es gaben häufig Fehler, die ein menschliches Eingreifen zur Überprüfung und Korrektur der Übersetzung erforderten [@Pierce1966; @Zong2022]. Der technische Fortschritt, insbesondere die Steigerung der Rechenleistung (bessere _Central Processing Unit_ und _Graphics Processing Unit_) und des Arbeitsspeichers hat dazu geführt, dass einerseits größere Datenmengen gespeichert werden konnten und andererseits den Umfang von statistischen Operationen über diese Daten erweitert werden konnten. Aus dieser Entwicklung ergibt sich Mitte der 1980er Jahre das _Recurrent Neural Network_ (RNN). Es beschreibt eine Methode, die Verhältnisse zwischen Begriffen in Sprachen auf der Grundlage der Modellierung von Verhältnissen zwischen Neuronen im menschlichen Gehirn auffasst. Mit der RNN-Methode können mehr Korrespondenzen zwischen Begriffen hergestellt -- das sog. _deep learning_ Ansatz  -- und gleichzeitig mit größeren Wortzusammenstellungen gearbeitet werden. Daraus sind ausgefeilteren Sprachmodellen wie etwa das Modell der bidirektionalen rekurrenten neuronalen Netzwerken (BRNN), das Langzeitgedächtnismodell (LSTM) oder das _gated recurrent units_ (GRUs) Modell konstruiert worden [siehe @Hochreiter1997]. Solche Modelle sind Matrixen von Verbindungen zwischen Begriffen, die nach einem Ähnlichkeitsansatz quantitativ gewertet werden. Begriffe, die stark verbunden sind, gelten als Begriffe, die auf ähnliche Inhalte verweisen. Begriffe, die dagegen schwach verbunden sind, verweisen auf unterschiedliche Inhalte. Ein solches Sprachmodell kann dann als eine Referenzmatrix verwendet werden, um weiter Sammlungen von sprachlichen Daten zu untersuchen und deren Inhalt zu werten.

Selbst mit der weiteren Entwicklung von Rechnern bleibt es jedoch schwierig, solche Sprachmodelle auf große Datensammlungen anzuwenden. Oft reichen die rechnerischen Kapazitäten oder die Speicherkapazitäten von gewöhnlichen Rechnern nicht aus. Anfang 2017 wurden deshalb GPT-Modelle entwickelt, die dieses Problem lösen sollten. Das innovative Merkmal von GPT-Modellen besteht darin, Matrixen von Begriffen nicht mit Sequenzen von Begriffen -- etwa mit Sätzen -- zu verbinden, sondern mit einzelnen Begriffen. Ein Transformer verbindet also ein Begriff mit den Begriffen, die am wahrscheinlichsten mit ihm in einer bestimmten Sprache auf der Grundlage von einer bestimmten Datensammlung verbunden sind. GPT-Modelle sind deshalb einerseits eine Erweiterung der Sprachmodelle, die nach einem _deep learning_ Ansatz konstruiert wurden. Andererseits besteht ihre Besonderheit darin, dass sie aufgrund von solche Matrixen die Wahrscheinlichkeit schneller und mit wenigen rechnerischen Kosten bestimmen können, dass ein Begriff _B_ nach einem Begriff _A_ auf der Grundlage von einem Kontext von Begriffen auftaucht, die am wahrscheinlichsten mit dem Begriff _A_ in einer gegebenen Sprache verbunden sind [siehe auch @Devlin2019]. In künftigen Versionen von solchen Transformern handelt es sich darum, das Ergebnis dieser Wahrscheinlichkeitsrechnung zu benutzen, um die Effizienz des Sprachmodells selbst bzw. um die Genauigkeit der Matrixen zu erhöhen, damit solche Wahrscheinlichkeitsrechnungen schneller und präziser erfolgen, ohne dass die rechnerischen Ressourcen zu sehr steigen. Bei Transformers geht es also um die Akkumulation von Dateien und von Verbindungen zwischen diesen Dateien, die erlauben, weitere Verbindungen zwischen diesen Dateien und entsprechend weitere Dateien aus diesen Verbindungen zu generieren. Solche Akkumulation anhand und in der Form von Mediationen zu entwickeln, sind jedoch nicht erst mit der wissenschaftlichen Arbeit an der KI entstanden. Sie stellen eine Grundtendenz beim Einbezug von Mediationen durch Akteure und gesellschaftliche Instanzen dar. Mediationen eröffnen Möglichkeiten zum weiteren Abgreifen von Verhältnissen, was die Akkumulationsmacht von Mediationen stärkt und zur Stärkung ihrer Symbolisierungsmacht und Formalisierungsmacht beiträgt. Dies macht Mediationen für Akteure und gesellschaftliche Instanzen attraktiv, auch wenn dabei sich diese Mediationen der Kontrolle von Akteuren und Instanzen immer mehr entziehen. Nehmen wir ein Beispiel, dass mit einer Grundlageoperation von Transformers verbunden ist: Lesen.

## Lesen

Transformers lesen Dateien, und wenn wir dieses Lesen von Außen betrachten würden, würden wir sagen, dass dieses Lesen nichts mit dem Lesen von Texten durch übliche menschlichen Akteuren gemein hat. Transformers nehmen Texte auf, die in diesem Sinne gelesen werden, dass sie von unerwünschten Zeichen und Begriffen gereinigt und in der Form von Vektoren dargestellt werden, die die Grundlage für die Berechnung von Verbindungen zwischen Begriffen und damit die notwendige Stufe zum Arrangement von solchen Verbindungen in der Form von einem anderen Text bereitstellen. Aus diesem Grund haben Transformers Debatten über den Wert nicht nur vom Lesen, sondern im Allgemeinen vom Wissen als Produktion aus der Interaktion zwischen Menschen und digitalen Technologien eingeführt, die teilweise auf die Debatten über verteilte Kognition in den Neuro- und Kognitionswissenschaften zurückgeht [@Magnus2007; @Michaelian2013; @Anderson2018; @Risku2020] sowie auf die Debatten zur Rolle von Algorithmen bei der Unterstützung menschlicher Entscheidungen zurückführen [@Pariser2012; @Anderson2012; @Braverman2014; @Bucher2018; @LeeLarsen2019]. Die Fragen, die sich in diesen Zusammenhängen stellen, betreffen den Wert von einer solchen Produktion vom Wissen und von dem entsprechenden Wissensinhalt, wenn diese nicht primär von menschlichen Akteuren, sondern maßgeblich von Mediationen produziert werden. Die Auseinandersetzung mit dem Lesen und seiner Geschichte sowie mit den Operationen, die mit dem Lesen verbunden sind, zeigt, dass solche Fragen nicht neu sind.

Soll es laut oder leise, schnell oder langsam gelesen werden? Hinter dieser Frage stecken Debatten zu der Entwicklung der Praktiken des Lesens, die nicht endgültig abgeschloßen werden können, aber die zu einigen gemeinsamen Ergebnissen Konvergieren. Ein erstes Ergebnis aus der Forschung zur "inneren" Geschichte des Lesens zeigt, dass es keine lineare Entwicklung der Praxis des Lesens gibt -- etwa wie vom lauten zu leisen Lesen [@Bickenbach2017]. Je nach Zeiten und Regionen wird





Entsprechend breiter und vielfältiger werden die Einsatzgebiete von solchen relationalen Dispositiven, weil die Mediationen, die sie ausmachen, nicht an bestimmten Zirkulationen, Sequenzen oder Relationsstrukturen gebunden sind, sondern dazu beitragen, dass relationale Dispositiven überall quer durch Sequenzen und Relationsstrukturen ausgebreitet werden können. Die Verwendung von Transformers auf Sammlungen von Dateien findet heute Anwendungen in allen einzelnen Tätigkeitsbereichen der Gesellschaft. Dies macht diese relationalen Dispositiven in ihrer Entwicklung und Verbreitung nicht nur von Zirkulationen, Sequenzen oder Relationsstrukturen unabhängig. Dies gibt ihnen ebenfalls eine relative Unabhängigkeitsmacht gegenüber Akteuren und Instanzen in Relationsstrukturen, weil sie einerseits Einschreibungsakte virtuell überall in Sequenzen und Relationsstrukturen ermöglichen, die die Einschreibung von Akteure und Instanzen in solchen Sequenzen und Relationsstrukturen weniger Zeit und Aufwand kostet, was andererseits jedoch voraussetzt, dass diese Akteure und Instanzen solche Einschreibungsakte weniger gut kontrollieren können. Die Kontrolle gehört dem relationalen Dispositiv als die konkrete Wirkung der Zusammenstellung von unterschiedlichen Mediationen an, die auf die Durchsetzung vom formalen Verfahren abzielt, das ein relationaler Dispositiv verkörpert und davon er die Bedeutung ausmacht. Im Fall von Transformers geht es um das Abgreifen der besten oder best möglichen Verbindungen zwischen Inhaltsteilen im Bezug auf eine Dateiensammlung, daraus Formalisierungsverfahren gestaltet werden -- einen Bericht schreiben, eine Statistik herstellen, eine Anwendung programmieren, ein Musikstück verfassen, ein Kunstwerk anfertigen usw. --, die einer Einschreibungsakte dienen. Was die beste oder best mögliche Verbindung bedeutet, ergibt sich vom Transformer, der in vielen Iterationsverfahren auf der Dateiensammlung all mögliche Verbindungen zwischen Inhaltsteilen probiert und prüft, bevor er sie von gut bis schlecht hierarchisiert. Diese Kontrolle ist die Auffassung der Reziprozität und die Grundlage der Legitimation von Akteure und Instanzen, die jede Art von Mediation in sich trägt, und die ihre Bedeutung als Alleinstellungs- und Hauptmerkmal der Medien orientierten Relationsstruktur findet. Durch die Verbreitung von relationalen Dispositiven und ihre Implementierung in den anderen Relationsstruktur verbreitet sich diese spezielle Bedeutung der Reziprozität auf die anderen Relationsstrukturen. Sie verdeutlich die Art und Weise, wie die Medien orientierte Relationsstruktur die drei anderen Relationsstrukturen satellisiert bzw. unter ihrer Kontrolle zu bringen versucht. Dabei macht sie gleichzeitig deutlich, das ihr Ideal der perfekten Relation das perfekte relationale Dispositiv ist, das in der Lage wäre, selbständige Einschreibungsakte als Ergebnis des eigenen Formalisierungsverfahrens überall in Relationsstrukturen jenseits der besonderen Merkmalen von Akteuren und von ihrer Zirkulation sowie von Instanzen und von ihrer Position in Sequenzen von solchen Relationsstrukturen. Nicht Akteure und Instanzen tätigen hier primär Einschreibungsakten, sondern Mediationen, die auf alle Akteure und Instanzen offen sind, und ihnen Kontrollemöglichkeiten anbieten, die zu Legitimationsmöglichkeiten entwickelt werden. In der Medien orientierten Relationsstruktur gipfelt dieses Selbstverständnis der Relationsstruktur in der Kernsequenz der Attraktivität als Attraktivität von Mediationen, die solche relationale Dispositiven unterstützen müssen, damit die Zirkulation in dieser Relationsstruktur gestärkt wird.

Die Grundeigenschaften von Transformers sind komplex, wenn man sich mit den unterschiedlichen Mediationen bzw. Parametern beschäftigt, die sie enthalten. Wenn man dagegen die Operationen berücksichtigt, die solche Mediationen durch ihre Parametern durchführen, zeigen Transformers grundsätzliche Ähnlichkeiten mit Mediationen, die zu den ersten relationalen Dispositiven entwickelt wurden, wie etwa Zitatspraktiken oder die Praxis des Exzerpierens. In dieser Hinsicht sind Transformers wie Zitatspraktiken und Praktiken des Exerpierens konkrete Mittel zur Investition in die Repräsentation der Attraktivität von Mediationen und deren funktionalen, formalen und relationalen Merkmalen.







Es geht grundsätzlicher um die Hierarchisierung von Mediationen als Prinzip der Durchsetzung derer Attraktivität zur Unterstützung der Verbreitung der medien-orientierten Relationsstruktur.

Diese Antwort entwickeln wir in diesem Kapitel am besonderen Beispiel des Plagiats, das mit der breiteren Frage der Legitimität von Wissen, von Akteuren, von Instanzen und von Mediationen des Wissens verbunden ist. Wenn wir das Plagiat durch Relation in Zirkulation denken, dann wird es deutlich, dass wir hier mit einer Praxis zu tun haben, die sehr lange Wurzel in der Geschichte hat und mit unterschiedlichen Formen des Umgangs mit Wissen, Wissensbeständen und Wissenstraditionen verbunden ist -- etwa das Kopieren, das Exzerpieren, das Kompilieren vom Wissen und von Wissensbeständen, die jede Form der Übertragung oder der Überlieferung vom Wissen und von Wissensbeständen zugrunde liegt.
